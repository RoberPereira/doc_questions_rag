{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.services.file_service import load_pdf, split_document\n",
    "from src.services.vectordb_service import ChromaDB\n",
    "from src.utils.util import pretty_print_docs\n",
    "from config import TEMPLATE, MODEL, DOC_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Use ONLY the following pieces of context to answer the question at the end.\\n'\n",
      " \"If you don't know the answer, just say that you don't know, NEVER make up an \"\n",
      " 'answer.\\n'\n",
      " 'Summarize in bullet point format. Keep the answer as concise as possible.\\n'\n",
      " '{context}\\n'\n",
      " 'Question: {question}\\n'\n",
      " 'Helpful Answer:')\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file xLSTM_paper.pdf ...\n",
      "File load correctly. Contains 55 pages\n"
     ]
    }
   ],
   "source": [
    "pages = load_pdf(doc_path=DOC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document spliting. Chunk size 800 - Chunk overlap 400 - Strategy recursive\n",
      "Splits generated 364\n",
      "Cleaning Chroma DB\n",
      "Creating a local embedding vector DB on directory data/chroma\n",
      "DB created successfuly. Collection count: 364 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_splits = split_document(pages, chunk_size=800, chunk_overlap=400, strategy='recursive')\n",
    "chroma = ChromaDB(text_splits)\n",
    "vectorstore = chroma.get_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the major improvments over the previous LSTM arquitecture?\"\n",
    "llm = ChatOpenAI(model_name=MODEL, temperature=0)\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(TEMPLATE)\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for search_type in ['similarity']: # 'mmr' \n",
    "    s_type = {}\n",
    "    retreiver = vectorstore.as_retriever(search_type=search_type)\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=retreiver,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    "    )\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    \n",
    "    s_type[search_type] = result\n",
    "    search_results.append(s_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMILARITY\n",
      "- Exponential gating and novel memory structures\n",
      "- Introduction of sLSTM with scalar memory, scalar update, and memory mixing\n",
      "- Introduction of mLSTM with matrix memory and covariance update rule, fully parallelizable\n",
      "- Integration of these LSTM extensions into residual block backbones to create xLSTM blocks and architectures\n"
     ]
    }
   ],
   "source": [
    "for search in search_results:\n",
    "    for key in search.keys():\n",
    "        print(str.upper(key))\n",
    "        print(search[key]['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMILARITY\n",
      "Document 1 page 0 from data/raw/xLSTM_paper.pdf:\n",
      "\n",
      "core marked the dawn of a new era, outpacing LSTMs at scale. We now raise a\n",
      "simple question: How far do we get in language modeling when scaling LSTMs to\n",
      "billions of parameters, leveraging the latest techniques from modern LLMs, but\n",
      "mitigating known limitations of LSTMs? Firstly, we introduce exponential gating\n",
      "with appropriate normalization and stabilization techniques. Secondly, we modify\n",
      "the LSTM memory structure, obtaining: (i) sLSTM with a scalar memory, a scalar\n",
      "update, and new memory mixing, (ii) mLSTM that is fully parallelizable with a\n",
      "matrix memory and a covariance update rule. Integrating these LSTM extensions\n",
      "into residual block backbones yields xLSTM blocks that are then residually stacked\n",
      "into xLSTM architectures. Exponential gating and modified memory structures\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2 page 2 from data/raw/xLSTM_paper.pdf:\n",
      "\n",
      "2 Extended Long Short-Term Memory\n",
      "To overcome the LSTM limitations, Extended Long Short-Term Memory (xLSTM) introduces two\n",
      "main modifications to the LSTM idea of Equation (1). Those modifications – exponential gating\n",
      "and novel memory structures – enrich the LSTM family by two members: (i) the new sLSTM (see\n",
      "Section 2.2) with a scalar memory, a scalar update, and memory mixing, and (ii) the new mLSTM\n",
      "(see Section 2.3) with a matrix memory and a covariance (outer product) update rule, which is fully\n",
      "parallelizable. Both sLSTM and mLSTM enhance the LSTM through exponential gating. To enable\n",
      "parallelization, the mLSTM abandons memory mixing, i.e., the hidden-hidden recurrent connections.\n",
      "Both mLSTM and sLSTM can be extended to multiple memory cells, where sLSTM features memory\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3 page 40 from data/raw/xLSTM_paper.pdf:\n",
      "\n",
      "up-projection backbone (see Figure 3) further boosts performance. Adding Exponential Gating to this\n",
      "architecture yields the sLSTM as depicted in Figure 9, with another large performance improvement.\n",
      "Finally, adding the best Matrix Memory variant found in Table 8 by replacing some sLSTM blocks\n",
      "with the mLSTM (see Figure 10) gives xLSTM[7:1] with the best performance.\n",
      "Details on Gating Technique Ablation Study. In Table 2 (bottom), we investigate the effect\n",
      "of trainable and input-dependent gates for mLSTM. The results show that, in contrast to other\n",
      "methods (Katharopoulos et al., 2020; Sun et al., 2023; Qin et al., 2023; Katsch, 2023; Yang et al.,\n",
      "2023; Qin et al., 2024; Peng et al., 2024), having the gates both learnable and input dependent gives\n",
      "the best results.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4 page 5 from data/raw/xLSTM_paper.pdf:\n",
      "\n",
      "xLSTM Architecture. An xLSTM architecture is constructed by residually stacking build-\n",
      "ing blocks (Srivastava et al., 2015; He et al., 2016). We rely on the most commonly used pre-\n",
      "LayerNorm (Ba et al., 2016b) residual backbones as used in contemporary Large Language Models.\n",
      "See last column in Figure 1.\n",
      "2.5 Memory and Speed Considerations\n",
      "Contrary to Transformers, xLSTM networks have a linear computation and a constant memory\n",
      "complexity with respect to the sequence length. Since the xLSTM memory is compressive, it is well\n",
      "suited for industrial applications and implementations on the edge.\n",
      "The memory of mLSTM does not require parameters but is computationally expensive through its d×d\n",
      "matrix memory and d×dupdate. We trade off memory capacity against computational complexity.\n"
     ]
    }
   ],
   "source": [
    "for search in search_results:\n",
    "    for key in search.keys():\n",
    "        print(str.upper(key))\n",
    "        pretty_print_docs(search[key]['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
